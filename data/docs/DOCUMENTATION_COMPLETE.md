# ğŸ¤– Documentation ComplÃ¨te - Bot Twitter AutomatisÃ©

## ğŸ“‹ Table des MatiÃ¨res

1. [ğŸš€ DÃ©marrage Rapide](#-dÃ©marrage-rapide)
2. [ğŸ“¦ Installation et Configuration](#-installation-et-configuration)
3. [ğŸ›ï¸ Utilisation](#-utilisation)
4. [ğŸ—ï¸ Architecture et SystÃ¨me Modulaire](#-architecture-et-systÃ¨me-modulaire)
5. [âš™ï¸ Configuration AvancÃ©e](#-configuration-avancÃ©e)
6. [ğŸ“Š Dashboard Web](#-dashboard-web)
7. [ğŸ¯ SystÃ¨me de Prompts](#-systÃ¨me-de-prompts)
8. [âš¡ Performance et Optimisation](#-performance-et-optimisation)
9. [ğŸ§ª Tests et Validation](#-tests-et-validation)
10. [ğŸ”§ DÃ©pannage](#-dÃ©pannage)
11. [ğŸ“ Changelog](#-changelog)

---

## ğŸš€ DÃ©marrage Rapide

### ğŸ¯ Lancement Ultra-Simple

```bash
# Option 1 : Lanceur unifiÃ© (RECOMMANDÃ‰)
python start.py                    # Mode complet (bot + dashboard)
python start.py --dashboard        # Dashboard seulement
python start.py --bot              # Bot seulement
python start.py --help             # Aide complÃ¨te

# Option 2 : Lanceur principal (Automatique)
python main.py                     # Bot + Dashboard automatique
```

### ğŸ“Š AccÃ¨s au Dashboard

Une fois lancÃ©, le dashboard est accessible via :
- **Local** : http://127.0.0.1:8080
- **RÃ©seau** : http://[IP_MACHINE]:8080

### ğŸ›‘ ArrÃªt
```bash
Ctrl + C  # ArrÃªte proprement bot ET dashboard
```

---

## ğŸ“¦ Installation et Configuration

### ğŸ”§ PrÃ©requis

```bash
# Installation des dÃ©pendances
pip install -r requirements.txt

# DÃ©pendances principales
pip install fastapi uvicorn websockets python-multipart
```

### ğŸ”‘ Variables d'Environnement (.env)

```env
# Configuration Twitter API
TWITTER_API_KEY=your_api_key
TWITTER_API_SECRET=your_api_secret
TWITTER_ACCESS_TOKEN=your_access_token
TWITTER_ACCESS_SECRET=your_access_secret

# Configuration LLM Provider
LLM_PROVIDER=auto                    # auto|openai|lmstudio

# Configuration OpenAI
OPENAI_API_KEY=your_openai_key

# Configuration LM Studio (minimal)
LM_API_URL=http://localhost:1234

# Configuration Base de DonnÃ©es
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key

# Configuration Dashboard (optionnel)
DASHBOARD_HOST=0.0.0.0
DASHBOARD_PORT=8080
DASHBOARD_DEBUG=false
```

### ğŸ“ Structure Configuration

```
config/
â”œâ”€â”€ config.json          # Configuration centralisÃ©e
â”œâ”€â”€ prompts.json         # Prompts et templates
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â””â”€â”€ setup.py            # Script d'installation
```

---

## ğŸ›ï¸ Utilisation

### ğŸš€ Modes de DÃ©marrage

#### Mode Complet (RecommandÃ©)
```bash
python start.py
# âœ… Bot Twitter actif
# âœ… Dashboard web accessible
# âœ… Monitoring temps rÃ©el
```

#### Mode Dashboard Seul
```bash
python start.py --dashboard
# âœ… Interface web seulement
# âœ… Consultation des mÃ©triques
# âœ… Configuration Ã  distance
```

#### Mode Bot Seul
```bash
python start.py --bot
# âœ… Bot Twitter seulement
# âŒ Pas d'interface web
# âœ… Fonctionnement en arriÃ¨re-plan
```

### ğŸ›ï¸ Options AvancÃ©es

```bash
# Port personnalisÃ©
python start.py --dashboard --port 9000

# Host personnalisÃ© (accÃ¨s rÃ©seau)
python start.py --dashboard --host 0.0.0.0 --port 8080

# Mode debug
python start.py --dashboard --debug
```

---

## ğŸ—ï¸ Architecture et SystÃ¨me Modulaire

### ğŸ“Š Vue d'Ensemble

```mermaid
graph TB
    A[start.py] --> B[Bot Twitter]
    A --> C[Dashboard Web]
    B --> D[LLM Provider Manager]
    D --> E[OpenAI Provider]
    D --> F[LM Studio Provider]
    B --> G[Reply Handler]
    B --> H[Content Generator]
    B --> I[Twitter API]
    C --> J[Metrics API]
    C --> K[Web Interface]
    
    style A fill:#e1f5fe
    style D fill:#c8e6c9
    style C fill:#fff3e0
```

### ğŸ¯ SystÃ¨me LLM Modulaire

#### Configuration Automatique
- **Mode Auto** : LM Studio (localhost) â†’ OpenAI (fallback)
- **Mode LM Studio** : Local uniquement avec auto-dÃ©tection modÃ¨les
- **Mode OpenAI** : Cloud API uniquement

#### Providers SupportÃ©s

**OpenAI Provider**
- **ModÃ¨les** : gpt-4o-mini, gpt-4o, gpt-4, gpt-3.5-turbo
- **Avantages** : FiabilitÃ©, qualitÃ© constante
- **API** : `https://api.openai.com/v1/chat/completions`

**LM Studio Provider**
- **ModÃ¨les** : Auto-dÃ©tection de tous modÃ¨les compatibles
- **Avantages** : Local, gratuit, personnalisable, zÃ©ro configuration
- **API** : `http://localhost:1234/v1/chat/completions`

### ğŸ”„ SystÃ¨me de Fallback Intelligent

1. **LM Studio (localhost)** : PrioritÃ© absolue
2. **LM Studio (IPs alternatives)** : Si configurÃ©es
3. **OpenAI** : Fallback final

---

## âš™ï¸ Configuration AvancÃ©e

### ğŸ¯ Configuration CentralisÃ©e

La configuration a Ã©tÃ© **entiÃ¨rement centralisÃ©e** dans `config/config.json` pour Ã©liminer toute redondance.

#### Structure config.json
```json
{
  "content_generation": {
    "provider": "auto",
    "model": "gpt-4o-mini", 
    "enable_images": true,
    "image_model": "dall-e-3",
    "max_tokens": 150,
    "temperature": 0.7,
    "auto_reply": {
      "provider": "auto",
      "model": "gpt-4o-mini",
      "max_tokens": 60,
      "temperature": 0.9,
      "force_llm": true
    },
    "tweet_generation": {
      "provider": "auto", 
      "model": "gpt-4o-mini",
      "max_tokens": 150,
      "temperature": 0.7
    }
  },
  "engagement": {
    "reply_check_interval_minutes": 60,
    "auto_like_replies": true
  },
  "monitoring": {
    "collect_stats": true,
    "stats_frequency_hours": 1,
    "daily_report": true,
    "report_time": "08:00"
  },
  "x_api": {
    "plan": "basic",
    "daily_post_limit": 100,
    "posts_per_day": 3,
    "posting_hours": {"start": "09:00", "end": "21:00"}
  }
}
```

### ğŸ® Gestionnaire Interactif

```bash
python tests/change_model_manager.py

# Options disponibles:
# 1. ğŸ¯ Configurer Provider (OpenAI/LM Studio)
# 2. ğŸŒ¡ï¸ Ajuster tempÃ©rature  
# 3. ğŸ§ª Tester les providers
# 4. ğŸ“Š Voir config complÃ¨te
# 5. ğŸ”„ RedÃ©marrer le bot
```

---

## ğŸ“Š Dashboard Web

### ğŸŒŸ FonctionnalitÃ©s Principales

#### Monitoring Temps RÃ©el
- âœ… **Statut du bot** (running/stopped/error)
- âœ… **Uptime** et mÃ©triques de performance
- âœ… **Tweets postÃ©s aujourd'hui**
- âœ… **Likes automatiques donnÃ©s**
- âœ… **RÃ©ponses traitÃ©es**
- âœ… **Utilisation des quotas X API**

#### Affichage Contenu
- âœ… **Dernier tweet postÃ©** avec engagement
- âœ… **Logs en temps rÃ©el** avec filtrage par niveau
- âœ… **Historique des tweets rÃ©cents**

### ğŸ¨ Interface Utilisateur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤– Twitter Bot Dashboard                   â”‚
â”‚  Monitoring en temps rÃ©el                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ğŸ“Š Statut Botâ”‚ğŸ“ˆ MÃ©triques â”‚âš¡ Quotas       â”‚
â”‚Ã‰tat: RUNNINGâ”‚Tweets: 3    â”‚Posts: 3/100    â”‚
â”‚Uptime: 2h34mâ”‚Likes: 47    â”‚Reads: 247/1440 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ğŸ¦ Dernier Tweet                            â”‚
â”‚"Solana ecosystem growing strong! ğŸš€"        â”‚
â”‚29/06/2025 14:23 - ID: 1234567890           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ğŸ“‹ Logs Temps RÃ©el                          â”‚
â”‚[14:25:32] INFO Bot started successfully    â”‚
â”‚[14:25:45] INFO Tweet posted successfully   â”‚
â”‚[14:26:01] INFO Reply liked automatically   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### âš¡ API REST

#### Endpoints Principaux
- **`GET /`** - Interface web principale
- **`GET /health`** - Status de santÃ© systÃ¨me
- **`GET /api/metrics`** - MÃ©triques complÃ¨tes JSON
- **`GET /api/logs`** - Logs rÃ©cents avec limite
- **`GET /api/tweets`** - Tweets rÃ©cents avec dÃ©tails

#### Exemple RÃ©ponse API
```json
{
  "success": true,
  "data": {
    "status": "running",
    "uptime": "2:34:56",
    "tweets_today": 3,
    "likes_today": 47,
    "replies_today": 12,
    "quota_usage": {
      "daily_usage": {"posts": 3, "reads": 247},
      "daily_limits": {"posts": 100, "reads": 1440}
    },
    "last_tweet": {
      "content": "Solana ecosystem growing! ğŸš€",
      "posted_at": "2025-06-29T14:23:00Z",
      "tweet_id": "1234567890"
    }
  }
}
```

---

## ğŸ¯ SystÃ¨me de Prompts

### ğŸ“ Architecture CentralisÃ©e

Le systÃ¨me de prompts unifie tous les prompts systÃ¨me, templates et configurations dans `prompts.json`.

#### Structure prompts.json
```json
{
  "system_prompts": {
    "tweet_generation": {
      "role": "system",
      "content": "You are an expert at creating viral content..."
    },
    "auto_reply": {
      "role": "system", 
      "content": "You are a crypto enthusiast engaging..."
    }
  },
  "user_prompts": {
    "tweet_generation": {
      "template": "Create a viral crypto tweet inspired by: {inspiration}..."
    },
    "auto_reply": {
      "template": "Someone replied: \"{reply_content}\". Generate a brief reply..."
    }
  },
  "templates": {
    "simple_replies": [
      "Thanks for engaging! ğŸ™ #Solana",
      "Appreciate the comment! ğŸ’ #SOL"
    ],
    "crypto_topics": [
      "Solana ecosystem growth",
      "DeFi innovation trends"
    ]
  }
}
```

### ğŸš€ Utilisation du PromptManager

```python
from core.prompt_manager import get_prompt_manager

pm = get_prompt_manager()

# System prompts pour OpenAI
system_prompt = pm.get_system_prompt("tweet_generation")

# User prompts avec variables
user_prompt = pm.get_user_prompt(
    "auto_reply",
    reply_content="Bitcoin going to moon!",
    username="cryptofan123"
)

# Templates
simple_replies = pm.get_simple_replies()
crypto_topics = pm.get_crypto_topics()
```

### ğŸ¤– RÃ©ponses GPT Contextuelles

#### Configuration pour RÃ©ponses Intelligentes
```json
{
  "settings": {
    "auto_reply": {
      "force_llm": true,      // Force GPT au lieu des templates
      "temperature": 0.9,     // CrÃ©ativitÃ© maximale
      "max_tokens": 60        // Format Twitter
    }
  }
}
```

#### Exemples de RÃ©ponses GÃ©nÃ©rÃ©es
```
Input: "Bitcoin is going to the moon! ğŸš€"
Output: "@username ğŸŒ• What catalyst do you think will send it there? #Bitcoin"

Input: "What's your opinion on DeFi protocols?"
Output: "@username ğŸŒŸ Love the tech discussion! Which protocol excites you most?"
```

---

## âš¡ Performance et Optimisation

### ğŸ“Š Optimisation des Logs

#### ProblÃ¨mes RÃ©solus
- âŒ **+1000 logs/heure** rÃ©pÃ©titifs (Dashboard, Reply Check)
- âŒ **Fichiers volumineux** (100+ MB/jour)
- âŒ **Difficile Ã  dÃ©bugger** Ã  cause du bruit

#### Solutions ImplÃ©mentÃ©es
- ğŸ”‡ **Dashboard HTTP logs** supprimÃ©s (`access_log=False`)
- ğŸ“‰ **Reply checks** : Log seulement si activitÃ© dÃ©tectÃ©e
- ğŸ¯ **Found replies** : Log seulement si replies > 0
- ğŸ”• **Librairies externes** : Tweepy/APScheduler en WARNING
- ğŸ§  **Log Optimizer** : Module intelligent (`core/log_optimizer.py`)

#### Impact Global
- ğŸ“Š **-85% volume logs** rÃ©pÃ©titifs
- ğŸ’¾ **~20 MB/jour** au lieu de 100 MB+
- ğŸ” **Meilleure lisibilitÃ©** pour debug
- âš¡ **Performance amÃ©liorÃ©e** (moins I/O)

### ğŸ“ˆ Performance Analytics

#### Score d'Engagement
**Formule de calcul** :
```
Score = (Likes Ã— 1) + (Retweets Ã— 3) + (RÃ©ponses Ã— 2) + (Impressions Ã— 0.01)
```

#### InterprÃ©tation
- ğŸ”¥ **Score > 100** : Performance exceptionnelle
- â­ **Score 50-100** : TrÃ¨s bonne performance  
- ğŸ‘ **Score 20-50** : Performance correcte
- ğŸ“Š **Score < 20** : Performance faible

#### Optimisation Quota Twitter
```json
{
  "engagement": {
    "reply_check_interval_minutes": 60  // Plan Basic: 60min, Pro: 15min
  },
  "monitoring": {
    "stats_frequency_hours": 1          // Collecte des stats
  }
}
```

---

## ğŸ§ª Tests et Validation

### ğŸ“‹ Suite de Tests ComplÃ¨te

#### Tests Principaux
```bash
# Test complet du systÃ¨me (sans API)
python tests/test_reply_system.py

# Test avec vraies donnÃ©es (consomme quotas)
python tests/test_live_replies.py

# Test du systÃ¨me modulaire LLM
python tests/test_modular_llm.py

# Test de centralisation config
python tests/test_centralized_config.py

# Test des prompts
python tests/test_prompts.py

# Test du dashboard
python tests/test_dashboard.py
```

#### Tests de Validation SpÃ©cifiques
```bash
# Fix des mentions
python tests/test_mention_fix_simple.py

# RÃ©ponses GPT
python tests/test_gpt_replies.py

# Configuration anglaise
python tests/test_english_prompts.py
```

### âœ… RÃ©sultats Attendus

**Test SystÃ¨me Modulaire** :
```
âœ… Gestionnaire LLM: RÃ‰USSI
âœ… IntÃ©gration ReplyHandler: RÃ‰USSI  
âœ… SystÃ¨me Fallback: RÃ‰USSI
âœ… Configuration Env: RÃ‰USSI

ğŸ¯ Score final: 4/4 tests rÃ©ussis
```

**Test Prompts CentralisÃ©s** :
```
âœ… LOADING: PASS
âœ… SYSTEM PROMPTS: PASS
âœ… USER PROMPTS: PASS
âœ… TEMPLATES: PASS
âœ… SETTINGS: PASS
âœ… IMAGE PROMPTS: PASS
âœ… HOT RELOAD: PASS

ğŸ‰ SystÃ¨me de prompts centralisÃ©s opÃ©rationnel !
```

---

## ğŸ”§ DÃ©pannage

### ğŸš¨ ProblÃ¨mes Courants

#### Dashboard ne dÃ©marre pas
```bash
# Solution 1: Installer les dÃ©pendances
pip install fastapi uvicorn websockets

# Solution 2: Port dÃ©jÃ  utilisÃ©
python start.py --dashboard --port 8081
```

#### Quota Twitter dÃ©passÃ©
```bash
# Augmenter interval reply check
"reply_check_interval_minutes": 120

# RÃ©duire frÃ©quence stats
"stats_frequency_hours": 6
```

#### LM Studio ne se connecte pas
```bash
# VÃ©rifier LM Studio lancÃ©
curl http://localhost:1234/v1/models

# Tester configuration
python tests/test_modular_llm.py
```

#### Erreurs d'import/modules
```bash
# VÃ©rifier structure
ls -la core/
ls -la config/

# RÃ©installer dÃ©pendances
pip install -r requirements.txt
```

#### Base de donnÃ©es Supabase
```bash
# VÃ©rifier variables .env
SUPABASE_URL=your_url
SUPABASE_KEY=your_key

# ExÃ©cuter script d'initialisation
psql -f scripts/sql/init_supabase.sql
```

### ğŸ¯ Fix des Mentions

#### ProblÃ¨me : Auto-mentions incorrectes
- **Avant** : `@MaxiMemeFeed Great analysis! ğŸš€` âŒ
- **AprÃ¨s** : `@cryptofan123 ğŸš€ Which catalyst do you think? ğŸŒ™` âœ…

#### Solution appliquÃ©e
- âœ… Prompts mis Ã  jour pour Ã©viter auto-mention
- âœ… RÃ©cupÃ©ration username Ã  partir d'author_id
- âœ… Instructions claires pour mentionner @username

### ğŸ“Š Monitoring Debug

```bash
# Logs en temps rÃ©el
tail -f logs/bot_*.log

# Logs spÃ©cifiques
tail -f logs/bot_*.log | grep "ERROR"
tail -f logs/bot_*.log | grep "stats"
tail -f logs/bot_*.log | grep "dashboard"
```

---

## ğŸ“ Changelog

### ğŸ”¥ Version 2.1.0 - Lanceur UnifiÃ© + Logs OptimisÃ©s (2025-01-20)

#### âœ¨ NouveautÃ©s Majeures

**ğŸš€ Lanceur UnifiÃ© - start.py**
- **SUPPRESSION** des 4 fichiers de lancement redondants (`go.py`, `launch.py`, `run.py`, ancien `main.py`)
- **NOUVEAU** : Un seul point d'entrÃ©e avec options flexibles
- **Interface simplifiÃ©e** pour tous les modes d'utilisation

**ğŸ¯ Modes de Lancement**
```bash
python start.py              # Mode complet (bot + dashboard)
python start.py --dashboard  # Dashboard seulement
python start.py --bot        # Bot seulement  
python start.py --help       # Aide complÃ¨te
```

#### ğŸ› ï¸ AmÃ©liorations Techniques

**Gestion d'Arguments**
- **argparse** intÃ©grÃ© pour parsing propre des options
- **Aide contextuelle** avec exemples d'utilisation
- **Validation des modes** mutuellement exclusifs

**Environnement AutomatisÃ©**
- **Auto-dÃ©tection** du rÃ©pertoire de travail
- **Configuration Python path** automatique
- **Gestion d'erreurs** robuste avec solutions suggÃ©rÃ©es

**Threading OptimisÃ©**
- **Dashboard en daemon thread** pour arrÃªt propre
- **DÃ©lai d'initialisation** contrÃ´lÃ© (3 secondes)
- **Gestion des signaux** Ctrl+C amÃ©liorÃ©e

#### ğŸ“Š Optimisation Logs (NOUVEAU)

**ProblÃ¨mes RÃ©solus**
- âŒ **+1000 logs/heure** rÃ©pÃ©titifs
- âŒ **Fichiers volumineux** (100+ MB/jour)
- âŒ **Difficile Ã  dÃ©bugger** Ã  cause du bruit

**Solutions ImplÃ©mentÃ©es**
- ğŸ”‡ **Dashboard HTTP logs** supprimÃ©s
- ğŸ“‰ **Reply checks** : Log seulement si activitÃ©
- ğŸ¯ **Found replies** : Log seulement si replies > 0
- ğŸ”• **Librairies externes** en WARNING
- ğŸ§  **Log Optimizer** intelligent

**Impact Global**
- ğŸ“Š **-85% volume logs** rÃ©pÃ©titifs
- ğŸ’¾ **~20 MB/jour** au lieu de 100 MB+
- ğŸ” **Meilleure lisibilitÃ©** pour debug
- âš¡ **Performance amÃ©liorÃ©e**

#### ğŸ”„ Migration et CompatibilitÃ©

**RÃ©trocompatibilitÃ©**
- `main.py` conservÃ© avec **redirection automatique** vers `start.py`
- **Messages informatifs** pour transition en douceur
- **Anciens workflows** continuent de fonctionner

**Suppression de Code Redondant**
- **~150 lignes** de code dupliquÃ© supprimÃ©es
- **Logique centralisÃ©e** dans un seul fichier
- **Maintenance simplifiÃ©e**

---

## ğŸ¯ RÃ©sumÃ© ExÃ©cutif

### âœ… FonctionnalitÃ©s ComplÃ¨tes

- ğŸš€ **Lanceur unifiÃ©** avec modes flexibles
- ğŸ“Š **Dashboard web** moderne avec monitoring temps rÃ©el
- ğŸ¤– **SystÃ¨me LLM modulaire** (OpenAI + LM Studio)
- ğŸ¯ **Prompts centralisÃ©s** et contextuels
- âš¡ **Logs optimisÃ©s** (-85% de bruit)
- ğŸ“ˆ **Analytics de performance** avec scoring
- ğŸ§ª **Suite de tests complÃ¨te**
- ğŸ”§ **Configuration centralisÃ©e**

### ğŸ† Avantages ClÃ©s

- **ğŸ¯ Source unique de vÃ©ritÃ©** pour toute la configuration
- âš¡ **Performance optimisÃ©e** avec rÃ©duction massive des logs
- ğŸ”„ **Fallback intelligent** entre providers LLM
- ğŸ“Š **Monitoring temps rÃ©el** avec interface moderne
- ğŸ§ª **Tests automatisÃ©s** pour validation continue
- ğŸ”§ **Maintenance simplifiÃ©e** avec code centralisÃ©

### ğŸš€ Prochaines Ã‰tapes

```bash
# DÃ©marrage immÃ©diat
python start.py

# AccÃ¨s dashboard
# â†’ http://localhost:8080

# Configuration interactive
python tests/change_model_manager.py

# Tests complets
python tests/test_modular_llm.py
```

**ğŸ‰ Votre bot Twitter est prÃªt pour la production !** 