#!/usr/bin/env python3
"""
Test complet du systÃ¨me modulaire LLM
OpenAI + LM Studio avec fallback automatique optimisÃ©
"""

import sys
import os
from pathlib import Path

# Ajouter le rÃ©pertoire parent/core au path
parent_dir = Path(__file__).parent.parent
sys.path.append(str(parent_dir / 'core'))

from llm_providers import get_llm_manager
from reply_handler import ReplyHandler
from storage import Reply
from datetime import datetime

def test_llm_manager():
    """Test le gestionnaire LLM modulaire"""
    print("ğŸ§ª TEST GESTIONNAIRE LLM MODULAIRE")
    print("=" * 50)
    
    try:
        # Initialiser le manager
        manager = get_llm_manager()
        
        # Afficher les infos
        info = manager.get_active_provider_info()
        print(f"ğŸ¯ Provider actif: {info['provider']}")
        print(f"ğŸ“¡ Disponible: {'âœ…' if info['available'] else 'âŒ'}")
        print(f"ğŸ¤– ModÃ¨les disponibles: {len(info['models'])}")
        
        if info['models']:
            print(f"   ğŸ“‹ Exemples: {', '.join(info['models'][:3])}...")
        
        if info['provider'] == 'lmstudio':
            active_url = info.get('active_url', 'N/A')
            print(f"ğŸ  URL LM Studio: {active_url}")
            print(f"ğŸ“¦ ModÃ¨le configurÃ©: {info.get('configured_model', 'N/A')}")
            
            # VÃ©rifier si on utilise localhost (optimal) ou alternative
            if 'localhost' in active_url or '127.0.0.1' in active_url:
                print(f"âœ… Utilise localhost (optimal)")
            else:
                print(f"âš ï¸ Utilise IP alternative (fallback)")
        
        # Test de gÃ©nÃ©ration directe
        print(f"\nğŸ”„ Test gÃ©nÃ©ration directe...")
        response = manager.generate_reply(
            system_prompt="You are a crypto expert bot.",
            user_prompt="What do you think about Bitcoin?",
            max_tokens=50,
            temperature=0.8
        )
        
        if response:
            print(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e: \"{response}\"")
            print(f"ğŸ“ Longueur: {len(response)} caractÃ¨res")
        else:
            print(f"âŒ Ã‰chec gÃ©nÃ©ration")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur manager: {e}")
        return False

def test_reply_handler_integration():
    """Test l'intÃ©gration avec ReplyHandler"""
    print(f"\nğŸ”— TEST INTÃ‰GRATION REPLY HANDLER")
    print("=" * 40)
    
    try:
        # Initialiser le reply handler
        reply_handler = ReplyHandler()
        
        # VÃ©rifier que le LLM manager est bien intÃ©grÃ©
        if hasattr(reply_handler, 'llm_manager'):
            print("âœ… LLM manager intÃ©grÃ© dans ReplyHandler")
        else:
            print("âŒ LLM manager manquant dans ReplyHandler")
            return False
        
        # Test avec diffÃ©rents types de messages
        test_cases = [
            {
                "content": "Bitcoin is going to the moon! ğŸš€",
                "description": "Message bullish"
            },
            {
                "content": "What's your opinion on DeFi protocols?",
                "description": "Question technique"
            },
            {
                "content": "Thanks for the great analysis! ğŸ’¯",
                "description": "Remerciement"
            }
        ]
        
        print(f"\nğŸ¯ Tests de rÃ©ponses contextuelles:")
        print("-" * 35)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nğŸ“ Test {i}: {test_case['description']}")
            print(f"ğŸ’¬ Message: \"{test_case['content']}\"")
            
            # CrÃ©er un objet Reply de test
            test_reply = Reply(
                reply_id=f"test_modular_{i}",
                original_tweet_id="test_tweet",
                author_id="test_user",
                content=test_case['content'],
                created_at=datetime.now()
            )
            
            try:
                # GÃ©nÃ©rer la rÃ©ponse via ReplyHandler
                response = reply_handler._generate_reply_content(test_reply)
                
                if response:
                    print(f"âœ… RÃ©ponse: \"{response}\"")
                    print(f"ğŸ“ Longueur: {len(response)} caractÃ¨res")
                    
                    # VÃ©rifier que c'est contextuel (pas une rÃ©ponse gÃ©nÃ©rique)
                    generic_words = ['thanks for engaging', 'great point', 'exactly']
                    is_contextual = not any(phrase in response.lower() for phrase in generic_words)
                    print(f"ğŸ¯ Contextuel: {'âœ…' if is_contextual else 'âŒ'}")
                    
                else:
                    print("âŒ Ã‰chec gÃ©nÃ©ration")
                    
            except Exception as e:
                print(f"âŒ Erreur: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur intÃ©gration: {e}")
        return False

def test_fallback_system():
    """Test le systÃ¨me de fallback optimisÃ©"""
    print(f"\nğŸ”„ TEST SYSTÃˆME FALLBACK OPTIMISÃ‰")
    print("=" * 35)
    
    try:
        manager = get_llm_manager()
        
        # Afficher l'ordre de prioritÃ©
        print(f"ğŸ¯ PrioritÃ© des providers:")
        for i, provider in enumerate(manager.provider_priority, 1):
            status = "âœ…" if provider in manager.providers else "âŒ"
            print(f"   {i}. {provider} {status}")
        
        # Info sur la logique de fallback LM Studio
        if 'lmstudio' in manager.providers:
            lm_provider = manager.providers['lmstudio']
            print(f"\nğŸ  LM Studio Fallback Logic:")
            print(f"   ğŸ“ URLs testÃ©es: {len(lm_provider.base_urls)}")
            for i, url in enumerate(lm_provider.base_urls, 1):
                is_active = url == lm_provider.active_url
                status = "ğŸ¯ ACTIF" if is_active else "ğŸ’¤ Standby"
                localhost_marker = "ğŸ  " if 'localhost' in url else "ğŸŒ "
                print(f"   {i}. {localhost_marker}{url} {status}")
        
        # Test de switch de provider si possible
        if len(manager.providers) > 1:
            print(f"\nğŸ”€ Test switch de provider...")
            current = manager.active_provider
            
            # Essayer de switcher vers l'autre provider
            for provider_name in manager.providers:
                if provider_name != current:
                    success = manager.switch_provider(provider_name)
                    if success:
                        print(f"âœ… Switch rÃ©ussi: {current} â†’ {provider_name}")
                        
                        # Tester gÃ©nÃ©ration avec nouveau provider
                        response = manager.generate_reply(
                            system_prompt="You are helpful.",
                            user_prompt="Say hi briefly",
                            max_tokens=20
                        )
                        
                        if response:
                            print(f"âœ… GÃ©nÃ©ration OK avec {provider_name}: \"{response}\"")
                        
                        # Retour au provider original
                        manager.switch_provider(current)
                        print(f"ğŸ”™ Retour Ã  {current}")
                        break
        else:
            print(f"â„¹ï¸ Un seul provider disponible, pas de test de switch")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur fallback: {e}")
        return False

def test_environment_config():
    """Test la configuration depuis .env"""
    print(f"\nğŸŒ TEST CONFIGURATION ENVIRONNEMENT")
    print("=" * 40)
    
    try:
        # VÃ©rifier les variables d'environnement LLM
        llm_vars = {
            'LLM_PROVIDER': os.getenv('LLM_PROVIDER', 'Non dÃ©fini'),
            'LM_API_URL': os.getenv('LM_API_URL', 'Non dÃ©fini'),
            'LM_ALTERNATIVE_IPS': os.getenv('LM_ALTERNATIVE_IPS', 'Non dÃ©fini'),
            'LM_MODEL_NAME': os.getenv('LM_MODEL_NAME', 'Non dÃ©fini'),
            'OPENAI_API_KEY': 'âœ… DÃ©fini' if os.getenv('OPENAI_API_KEY') else 'âŒ Manquant'
        }
        
        print(f"ğŸ“‹ Variables d'environnement:")
        for key, value in llm_vars.items():
            print(f"   {key}: {value}")
        
        # Analyse de la configuration LM Studio
        lm_url = os.getenv('LM_API_URL', 'http://localhost:1234')
        alt_ips = os.getenv('LM_ALTERNATIVE_IPS', '')
        
        print(f"\nğŸ  Analyse configuration LM Studio:")
        if 'localhost' in lm_url:
            print(f"   âœ… URL principale: localhost (optimal)")
        else:
            print(f"   âš ï¸ URL principale: {lm_url} (non-localhost)")
        
        if alt_ips and alt_ips.strip():
            alt_count = len([ip.strip() for ip in alt_ips.split(',') if ip.strip()])
            print(f"   ğŸ”„ IPs alternatives: {alt_count} configurÃ©es (fallback seulement)")
        else:
            print(f"   âœ… Pas d'IPs alternatives (localhost suffit)")
        
        # VÃ©rifier cohÃ©rence avec provider actif
        manager = get_llm_manager()
        provider_env = os.getenv('LLM_PROVIDER', 'auto').lower()
        active_provider = manager.active_provider
        
        print(f"\nğŸ”„ CohÃ©rence configuration:")
        print(f"   ENV LLM_PROVIDER: {provider_env}")
        print(f"   Provider actif: {active_provider}")
        
        if provider_env == "auto":
            print(f"   âœ… Mode auto - provider optimal sÃ©lectionnÃ©")
        elif provider_env == active_provider:
            print(f"   âœ… Configuration cohÃ©rente")
        else:
            print(f"   âš ï¸ IncohÃ©rence dÃ©tectÃ©e")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur config: {e}")
        return False

def main():
    """Test complet du systÃ¨me modulaire"""
    print("ğŸ¤– TEST COMPLET SYSTÃˆME LLM MODULAIRE OPTIMISÃ‰")
    print("=" * 65)
    
    tests = [
        ("Gestionnaire LLM", test_llm_manager),
        ("IntÃ©gration ReplyHandler", test_reply_handler_integration),
        ("SystÃ¨me Fallback OptimisÃ©", test_fallback_system),
        ("Configuration Env", test_environment_config)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*65}")
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"âŒ Erreur critique dans {test_name}: {e}")
            results[test_name] = False
    
    # RÃ©sumÃ© final
    print(f"\n{'='*65}")
    print(f"ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("="*30)
    
    passed = 0
    for test_name, result in results.items():
        status = "âœ… RÃ‰USSI" if result else "âŒ Ã‰CHEC"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ Score final: {passed}/{len(tests)} tests rÃ©ussis")
    
    if passed == len(tests):
        print(f"ğŸ‰ SYSTÃˆME MODULAIRE ENTIÃˆREMENT OPÃ‰RATIONNEL!")
        print(f"ğŸš€ OptimisÃ©: localhost prioritaire, alternatives en fallback")
        print(f"ğŸ’« PrÃªt pour utilisation en production")
    else:
        print(f"âš ï¸ Quelques ajustements nÃ©cessaires")
    
    print(f"\nğŸ’¡ Pour configurer: python tests/change_model_manager.py")

if __name__ == "__main__":
    main() 