#!/usr/bin/env python3
"""
Test complet du syst√®me modulaire LLM
OpenAI + LM Studio avec fallback automatique optimis√©
"""

import sys
import os
from pathlib import Path

# Ajouter le r√©pertoire parent/core au path
parent_dir = Path(__file__).parent.parent
sys.path.append(str(parent_dir / 'core'))

from llm_providers import get_llm_manager
from reply_handler import ReplyHandler
from storage import Reply
from datetime import datetime

def test_llm_manager():
    """Test le gestionnaire LLM modulaire"""
    print("üß™ TEST GESTIONNAIRE LLM MODULAIRE")
    print("=" * 50)
    
    try:
        # Initialiser le manager
        manager = get_llm_manager()
        
        # Afficher les infos
        info = manager.get_active_provider_info()
        print(f"üéØ Provider actif: {info['provider']}")
        print(f"üì° Disponible: {'‚úÖ' if info['available'] else '‚ùå'}")
        print(f"ü§ñ Mod√®les disponibles: {len(info['models'])}")
        
        if info['models']:
            print(f"   üìã Exemples: {', '.join(info['models'][:3])}...")
        
        if info['provider'] == 'lmstudio':
            active_url = info.get('active_url', 'N/A')
            print(f"üè† URL LM Studio: {active_url}")
            print(f"üì¶ Mod√®le configur√©: {info.get('configured_model', 'N/A')}")
            
            # V√©rifier si on utilise localhost (optimal) ou alternative
            if 'localhost' in active_url or '127.0.0.1' in active_url:
                print(f"‚úÖ Utilise localhost (optimal)")
            else:
                print(f"‚ö†Ô∏è Utilise IP alternative (fallback)")
        
        # Test de g√©n√©ration directe
        print(f"\nüîÑ Test g√©n√©ration directe...")
        response = manager.generate_reply(
            system_prompt="You are a crypto expert bot.",
            user_prompt="What do you think about Bitcoin?",
            max_tokens=50,
            temperature=0.8
        )
        
        if response:
            print(f"‚úÖ R√©ponse g√©n√©r√©e: \"{response}\"")
            print(f"üìè Longueur: {len(response)} caract√®res")
        else:
            print(f"‚ùå √âchec g√©n√©ration")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur manager: {e}")
        return False

def test_reply_handler_integration():
    """Test l'int√©gration avec ReplyHandler"""
    print(f"\nüîó TEST INT√âGRATION REPLY HANDLER")
    print("=" * 40)
    
    try:
        # Initialiser le reply handler
        reply_handler = ReplyHandler()
        
        # V√©rifier que le LLM manager est bien int√©gr√©
        if hasattr(reply_handler, 'llm_manager'):
            print("‚úÖ LLM manager int√©gr√© dans ReplyHandler")
        else:
            print("‚ùå LLM manager manquant dans ReplyHandler")
            return False
        
        # Test avec diff√©rents types de messages
        test_cases = [
            {
                "content": "Bitcoin is going to the moon! üöÄ",
                "description": "Message bullish"
            },
            {
                "content": "What's your opinion on DeFi protocols?",
                "description": "Question technique"
            },
            {
                "content": "Thanks for the great analysis! üíØ",
                "description": "Remerciement"
            }
        ]
        
        print(f"\nüéØ Tests de r√©ponses contextuelles:")
        print("-" * 35)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nüìù Test {i}: {test_case['description']}")
            print(f"üí¨ Message: \"{test_case['content']}\"")
            
            # Cr√©er un objet Reply de test
            test_reply = Reply(
                reply_id=f"test_modular_{i}",
                original_tweet_id="test_tweet",
                author_id="test_user",
                content=test_case['content'],
                created_at=datetime.now()
            )
            
            try:
                # G√©n√©rer la r√©ponse via ReplyHandler
                response = reply_handler._generate_reply_content(test_reply)
                
                if response:
                    print(f"‚úÖ R√©ponse: \"{response}\"")
                    print(f"üìè Longueur: {len(response)} caract√®res")
                    
                    # V√©rifier que c'est contextuel (pas une r√©ponse g√©n√©rique)
                    generic_words = ['thanks for engaging', 'great point', 'exactly']
                    is_contextual = not any(phrase in response.lower() for phrase in generic_words)
                    print(f"üéØ Contextuel: {'‚úÖ' if is_contextual else '‚ùå'}")
                    
                else:
                    print("‚ùå √âchec g√©n√©ration")
                    
            except Exception as e:
                print(f"‚ùå Erreur: {e}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur int√©gration: {e}")
        return False

def test_fallback_system():
    """Test le syst√®me de fallback optimis√©"""
    print(f"\nüîÑ TEST SYST√àME FALLBACK OPTIMIS√â")
    print("=" * 35)
    
    try:
        manager = get_llm_manager()
        
        # Afficher l'ordre de priorit√©
        print(f"üéØ Priorit√© des providers:")
        for i, provider in enumerate(manager.provider_priority, 1):
            status = "‚úÖ" if provider in manager.providers else "‚ùå"
            print(f"   {i}. {provider} {status}")
        
        # Info sur la logique de fallback LM Studio
        if 'lmstudio' in manager.providers:
            lm_provider = manager.providers['lmstudio']
            print(f"\nüè† LM Studio Fallback Logic:")
            print(f"   üìç URLs test√©es: {len(lm_provider.base_urls)}")
            for i, url in enumerate(lm_provider.base_urls, 1):
                is_active = url == lm_provider.active_url
                status = "üéØ ACTIF" if is_active else "üí§ Standby"
                localhost_marker = "üè† " if 'localhost' in url else "üåê "
                print(f"   {i}. {localhost_marker}{url} {status}")
        
        # Test de switch de provider si possible
        if len(manager.providers) > 1:
            print(f"\nüîÄ Test switch de provider...")
            current = manager.active_provider
            
            # Essayer de switcher vers l'autre provider
            for provider_name in manager.providers:
                if provider_name != current:
                    success = manager.switch_provider(provider_name)
                    if success:
                        print(f"‚úÖ Switch r√©ussi: {current} ‚Üí {provider_name}")
                        
                        # Tester g√©n√©ration avec nouveau provider
                        response = manager.generate_reply(
                            system_prompt="You are helpful.",
                            user_prompt="Say hi briefly",
                            max_tokens=20
                        )
                        
                        if response:
                            print(f"‚úÖ G√©n√©ration OK avec {provider_name}: \"{response}\"")
                        
                        # Retour au provider original
                        manager.switch_provider(current)
                        print(f"üîô Retour √† {current}")
                        break
        else:
            print(f"‚ÑπÔ∏è Un seul provider disponible, pas de test de switch")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur fallback: {e}")
        return False

def test_environment_config():
    """Test la configuration depuis .env"""
    print(f"\nüåç TEST CONFIGURATION ENVIRONNEMENT")
    print("=" * 40)
    
    try:
        # V√©rifier les variables d'environnement LLM
        llm_vars = {
            'LLM_PROVIDER': os.getenv('LLM_PROVIDER', 'Non d√©fini'),
            'LM_API_URL': os.getenv('LM_API_URL', 'Non d√©fini'),
            'LM_ALTERNATIVE_IPS': os.getenv('LM_ALTERNATIVE_IPS', 'Non d√©fini'),
            'LM_MODEL_NAME': os.getenv('LM_MODEL_NAME', 'Non d√©fini'),
            'OPENAI_API_KEY': '‚úÖ D√©fini' if os.getenv('OPENAI_API_KEY') else '‚ùå Manquant'
        }
        
        print(f"üìã Variables d'environnement:")
        for key, value in llm_vars.items():
            print(f"   {key}: {value}")
        
        # Analyse de la configuration LM Studio
        lm_url = os.getenv('LM_API_URL', 'http://localhost:1234')
        alt_ips = os.getenv('LM_ALTERNATIVE_IPS', '')
        
        print(f"\nüè† Analyse configuration LM Studio:")
        if 'localhost' in lm_url:
            print(f"   ‚úÖ URL principale: localhost (optimal)")
        else:
            print(f"   ‚ö†Ô∏è URL principale: {lm_url} (non-localhost)")
        
        if alt_ips and alt_ips.strip():
            alt_count = len([ip.strip() for ip in alt_ips.split(',') if ip.strip()])
            print(f"   üîÑ IPs alternatives: {alt_count} configur√©es (fallback seulement)")
        else:
            print(f"   ‚úÖ Pas d'IPs alternatives (localhost suffit)")
        
        # V√©rifier coh√©rence avec provider actif
        manager = get_llm_manager()
        provider_env = os.getenv('LLM_PROVIDER', 'auto').lower()
        active_provider = manager.active_provider
        
        print(f"\nüîÑ Coh√©rence configuration:")
        print(f"   ENV LLM_PROVIDER: {provider_env}")
        print(f"   Provider actif: {active_provider}")
        
        if provider_env == "auto":
            print(f"   ‚úÖ Mode auto - provider optimal s√©lectionn√©")
        elif provider_env == active_provider:
            print(f"   ‚úÖ Configuration coh√©rente")
        else:
            print(f"   ‚ö†Ô∏è Incoh√©rence d√©tect√©e")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur config: {e}")
        return False

def main():
    """Test complet du syst√®me modulaire"""
    print("ü§ñ TEST COMPLET SYST√àME LLM MODULAIRE OPTIMIS√â")
    print("=" * 65)
    
    tests = [
        ("Gestionnaire LLM", test_llm_manager),
        ("Int√©gration ReplyHandler", test_reply_handler_integration),
        ("Syst√®me Fallback Optimis√©", test_fallback_system),
        ("Configuration Env", test_environment_config)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*65}")
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"‚ùå Erreur critique dans {test_name}: {e}")
            results[test_name] = False
    
    # R√©sum√© final
    print(f"\n{'='*65}")
    print(f"üìä R√âSUM√â DES TESTS")
    print("="*30)
    
    passed = 0
    for test_name, result in results.items():
        status = "‚úÖ R√âUSSI" if result else "‚ùå √âCHEC"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nüéØ Score final: {passed}/{len(tests)} tests r√©ussis")
    
    if passed == len(tests):
        print(f"üéâ SYST√àME MODULAIRE ENTI√àREMENT OP√âRATIONNEL!")
        print(f"üöÄ Optimis√©: localhost prioritaire, alternatives en fallback")
        print(f"üí´ Pr√™t pour utilisation en production")
    else:
        print(f"‚ö†Ô∏è Quelques ajustements n√©cessaires")
    
    print(f"\nüí° Pour configurer: python tests/change_model_manager.py")

if __name__ == "__main__":
    main() 