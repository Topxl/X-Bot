# Configuration LLM Provider
# Choisir: auto, openai, lmstudio
LLM_PROVIDER=auto

# Configuration OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# Configuration LM Studio
# URL de votre instance LM Studio (localhost par défaut)
LM_API_URL=http://localhost:1234

# Configuration optionnelle (seulement si nécessaire):
# LM_ALTERNATIVE_IPS=192.168.1.34,192.168.1.33  # IPs de fallback
# LM_MODEL_NAME=nom-modele-specifique             # Forcer un modèle

# Configuration Twitter API
TWITTER_BEARER_TOKEN=your_bearer_token
TWITTER_API_KEY=your_api_key
TWITTER_API_SECRET=your_api_secret
TWITTER_ACCESS_TOKEN=your_access_token
TWITTER_ACCESS_TOKEN_SECRET=your_access_token_secret

# Configuration Supabase (optionnel)
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key

# Configuration bot
BOT_USERNAME=your_bot_username

# Optional
LOG_LEVEL=INFO
ENVIRONMENT=development
