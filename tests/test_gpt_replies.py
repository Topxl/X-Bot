#!/usr/bin/env python3
"""
Test des r√©ponses GPT contextuelles
V√©rifie la qualit√© et la vari√©t√© des r√©ponses g√©n√©r√©es
"""

import sys
import os
from pathlib import Path

# Ajouter le r√©pertoire parent/core au path
parent_dir = Path(__file__).parent.parent
sys.path.append(str(parent_dir / 'core'))

from llm_providers import get_llm_manager
from storage import Reply
from datetime import datetime

def test_contextual_responses():
    """Test la g√©n√©ration de r√©ponses contextuelles"""
    print("üß™ TEST R√âPONSES GPT CONTEXTUELLES")
    print("=" * 50)
    
    try:
        # Initialiser le manager LLM
        manager = get_llm_manager()
        
        # Cas de test avec diff√©rents types de tweets
        test_cases = [
            {
                "category": "Message Bullish",
                "content": "Bitcoin is going to the moon! üöÄ",
                "expected_keywords": ["moon", "bitcoin", "btc", "üöÄ", "üåï", "bull"]
            },
            {
                "category": "Question Technique", 
                "content": "What's your opinion on DeFi protocols?",
                "expected_keywords": ["defi", "protocol", "opinion", "think", "experience"]
            },
            {
                "category": "Analyse March√©",
                "content": "Market is looking bearish today üìâ",
                "expected_keywords": ["bear", "market", "dip", "üìâ", "buy", "hodl"]
            },
            {
                "category": "Remerciement",
                "content": "Thanks for the great analysis! üíØ",
                "expected_keywords": ["thanks", "analysis", "helpful", "üíØ", "glad"]
            }
        ]
        
        print(f"üéØ Test de {len(test_cases)} types de messages:")
        print("-" * 45)
        
        results = []
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\nüìù Test {i}: {test_case['category']}")
            print(f"üí¨ Input: \"{test_case['content']}\"")
            
            # G√©n√©rer la r√©ponse
            system_prompt = """You are MaxiMeme, a crypto expert bot on Twitter.
            Respond in French, keep it under 60 characters, be contextual and engaging.
            Use relevant emojis and ask follow-up questions."""
            
            user_prompt = f"Respond to this tweet: {test_case['content']}"
            
            try:
                response = manager.generate_reply(
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    max_tokens=60,
                    temperature=0.9
                )
                
                if response:
                    print(f"‚úÖ Output: \"{response}\"")
                    print(f"üìè Longueur: {len(response)} caract√®res")
                    
                    # Analyser la contextualit√©
                    response_lower = response.lower()
                    content_lower = test_case['content'].lower()
                    
                    # V√©rifier si c'est contextuel (contient des mots-cl√©s pertinents)
                    contextual_score = 0
                    matched_keywords = []
                    
                    for keyword in test_case['expected_keywords']:
                        if keyword.lower() in response_lower:
                            contextual_score += 1
                            matched_keywords.append(keyword)
                    
                    # V√©rifier que ce n'est pas une r√©ponse g√©n√©rique
                    generic_phrases = [
                        "thanks for engaging", "great point", "keep it up",
                        "exactly", "totally agree", "nice share"
                    ]
                    
                    is_generic = any(phrase in response_lower for phrase in generic_phrases)
                    
                    print(f"üéØ Mots-cl√©s pertinents: {matched_keywords}")
                    print(f"üìä Score contextuel: {contextual_score}/{len(test_case['expected_keywords'])}")
                    print(f"üé≠ G√©n√©rique: {'‚ùå Oui' if is_generic else '‚úÖ Non'}")
                    
                    # √âvaluation globale
                    is_good = (
                        contextual_score > 0 and 
                        not is_generic and 
                        len(response) <= 200  # Longueur Twitter appropri√©e
                    )
                    
                    print(f"üèÜ Qualit√©: {'‚úÖ Excellente' if is_good else '‚ö†Ô∏è √Ä am√©liorer'}")
                    
                    results.append({
                        'category': test_case['category'],
                        'response': response,
                        'contextual_score': contextual_score,
                        'is_generic': is_generic,
                        'is_good': is_good
                    })
                    
                else:
                    print("‚ùå Aucune r√©ponse g√©n√©r√©e")
                    results.append({
                        'category': test_case['category'],
                        'response': None,
                        'is_good': False
                    })
                    
            except Exception as e:
                print(f"‚ùå Erreur g√©n√©ration: {e}")
                results.append({
                    'category': test_case['category'],
                    'response': None,
                    'is_good': False
                })
        
        return results
        
    except Exception as e:
        print(f"‚ùå Erreur test contextuel: {e}")
        return []

def test_response_variety():
    """Test la vari√©t√© des r√©ponses (pas de r√©p√©tition)"""
    print(f"\nüé≠ TEST VARI√âT√â DES R√âPONSES")
    print("=" * 35)
    
    try:
        manager = get_llm_manager()
        
        # M√™me message g√©n√©r√© plusieurs fois
        test_message = "Bitcoin is pumping hard today! üöÄ"
        responses = []
        
        print(f"üí¨ Message test: \"{test_message}\"")
        print(f"üîÑ G√©n√©ration de 3 r√©ponses diff√©rentes...\n")
        
        for i in range(3):
            response = manager.generate_reply(
                system_prompt="You are MaxiMeme. Respond in French, be contextual and varied.",
                user_prompt=f"Respond to: {test_message}",
                max_tokens=60,
                temperature=0.9
            )
            
            if response:
                responses.append(response)
                print(f"üéØ R√©ponse {i+1}: \"{response}\"")
            else:
                print(f"‚ùå R√©ponse {i+1}: √âchec")
        
        # Analyser la vari√©t√©
        if len(responses) >= 2:
            unique_responses = len(set(responses))
            variety_score = unique_responses / len(responses) * 100
            
            print(f"\nüìä Analyse vari√©t√©:")
            print(f"   üìù R√©ponses g√©n√©r√©es: {len(responses)}")
            print(f"   üé≠ R√©ponses uniques: {unique_responses}")
            print(f"   üìà Score vari√©t√©: {variety_score:.1f}%")
            
            if variety_score >= 80:
                print(f"   ‚úÖ Excellente vari√©t√©!")
            elif variety_score >= 60:
                print(f"   ‚ö†Ô∏è Vari√©t√© acceptable")
            else:
                print(f"   ‚ùå Trop de r√©p√©titions")
            
            return variety_score >= 60
        else:
            print("‚ùå Pas assez de r√©ponses pour tester la vari√©t√©")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur test vari√©t√©: {e}")
        return False

def main():
    """Test complet des r√©ponses GPT"""
    print("ü§ñ TEST COMPLET R√âPONSES GPT")
    print("=" * 45)
    
    # Test 1: R√©ponses contextuelles
    contextual_results = test_contextual_responses()
    
    # Test 2: Vari√©t√© des r√©ponses
    variety_result = test_response_variety()
    
    # R√©sum√© final
    print(f"\n{'='*45}")
    print(f"üìä R√âSUM√â DES TESTS GPT")
    print("="*30)
    
    if contextual_results:
        good_responses = [r for r in contextual_results if r.get('is_good', False)]
        print(f"üéØ R√©ponses contextuelles: {len(good_responses)}/{len(contextual_results)}")
        
        for result in contextual_results:
            status = "‚úÖ" if result.get('is_good', False) else "‚ùå"
            print(f"   {status} {result['category']}")
    
    variety_status = "‚úÖ" if variety_result else "‚ùå"
    print(f"üé≠ Vari√©t√© des r√©ponses: {variety_status}")
    
    # Score global
    if contextual_results:
        good_count = len([r for r in contextual_results if r.get('is_good', False)])
        total_count = len(contextual_results)
        success_rate = good_count / total_count if total_count > 0 else 0
        
        print(f"\nüèÜ Score global: {good_count}/{total_count} ({success_rate:.1%})")
        
        if success_rate >= 0.8 and variety_result:
            print(f"üéâ R√âPONSES GPT EXCELLENTES!")
            print(f"‚úÖ Contextuelles, vari√©es, et engageantes")
        elif success_rate >= 0.6:
            print(f"‚ö†Ô∏è R√©ponses GPT correctes mais perfectibles")
        else:
            print(f"‚ùå R√©ponses GPT n√©cessitent am√©lioration")
    
    print(f"\nüí° Pour am√©liorer:")
    print(f"   ‚Ä¢ Ajuster temp√©rature dans prompts.json")
    print(f"   ‚Ä¢ Optimiser les prompts syst√®me") 
    print(f"   ‚Ä¢ V√©rifier force_llm: true")

if __name__ == "__main__":
    main() 