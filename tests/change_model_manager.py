#!/usr/bin/env python3
"""
Gestionnaire de modÃ¨les LLM modulaire
Support: OpenAI, LM Studio, et configuration .env
OptimisÃ©: LM_ALTERNATIVE_IPS utilisÃ©es seulement si localhost Ã©choue
"""

import json
import os
import sys
from pathlib import Path
import subprocess

def load_prompts():
    """Charge le fichier prompts.json"""
    prompts_file = Path("../config/prompts.json") if Path("../config/prompts.json").exists() else Path("config/prompts.json")
    if not prompts_file.exists():
        print("âŒ Fichier config/prompts.json non trouvÃ©")
        return None
    
    with open(prompts_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_prompts(data):
    """Sauvegarde le fichier prompts.json"""
    prompts_file = Path("../config/prompts.json") if Path("../config/prompts.json").exists() else Path("config/prompts.json")
    with open(prompts_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def load_env():
    """Charge le fichier .env"""
    env_file = Path("../.env") if Path("../.env").exists() else Path(".env")
    env_vars = {}
    
    if env_file.exists():
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    
    return env_vars

def save_env(env_vars):
    """Sauvegarde le fichier .env"""
    env_file = Path("../.env") if Path("../.env").exists() else Path(".env")
    with open(env_file, 'w', encoding='utf-8') as f:
        f.write("# Configuration LLM Provider\n")
        f.write("# Choisir: auto, openai, lmstudio\n")
        f.write(f"LLM_PROVIDER={env_vars.get('LLM_PROVIDER', 'auto')}\n\n")
        
        f.write("# Configuration OpenAI\n")
        f.write(f"OPENAI_API_KEY={env_vars.get('OPENAI_API_KEY', '')}\n\n")
        
        f.write("# Configuration LM Studio\n")
        f.write(f"LM_API_URL={env_vars.get('LM_API_URL', 'http://localhost:1234')}\n")
        if 'LM_ALTERNATIVE_IPS' in env_vars and env_vars['LM_ALTERNATIVE_IPS'].strip():
            f.write(f"LM_ALTERNATIVE_IPS={env_vars['LM_ALTERNATIVE_IPS']}\n")
        f.write("# LM_ALTERNATIVE_IPS=192.168.1.34,192.168.1.33  # Optionnel - fallback IPs\n")
        if 'LM_MODEL_NAME' in env_vars:
            f.write(f"LM_MODEL_NAME={env_vars['LM_MODEL_NAME']}\n")
        f.write("# LM_MODEL_NAME=nom-modele-specifique  # Optionnel - auto-dÃ©tectÃ© si non spÃ©cifiÃ©\n\n")
        
        # Autres variables existantes
        for key, value in env_vars.items():
            if not key.startswith(('LLM_', 'OPENAI_', 'LM_')):
                f.write(f"{key}={value}\n")

def show_current_config():
    """Affiche la configuration actuelle"""
    print("ğŸ”§ CONFIGURATION ACTUELLE:")
    print("=" * 50)
    
    # Prompts config
    data = load_prompts()
    if data:
        settings = data["settings"]["auto_reply"]
        print(f"ğŸ“‹ Prompts.json:")
        print(f"   ğŸ¤– Provider: {settings.get('provider', 'auto')}")
        print(f"   ğŸ“± ModÃ¨le: {settings['model']}")
        print(f"   ğŸ›ï¸ TempÃ©rature: {settings['temperature']}")
        print(f"   ğŸ“ Max tokens: {settings['max_tokens']}")
    
    # Env config
    env_vars = load_env()
    print(f"\nğŸŒ Variables d'environnement:")
    print(f"   ğŸ¯ LLM_PROVIDER: {env_vars.get('LLM_PROVIDER', 'auto')}")
    print(f"   ğŸ”‘ OPENAI_API_KEY: {'âœ… ConfigurÃ©' if env_vars.get('OPENAI_API_KEY') else 'âŒ Manquant'}")
    print(f"   ğŸ  LM_API_URL: {env_vars.get('LM_API_URL', 'http://localhost:1234')}")
    
    alt_ips = env_vars.get('LM_ALTERNATIVE_IPS', '')
    if alt_ips and alt_ips.strip():
        print(f"   ğŸ”„ LM_ALTERNATIVE_IPS: {alt_ips} (fallback si localhost Ã©choue)")
    else:
        print(f"   ğŸ”„ LM_ALTERNATIVE_IPS: âœ… Non nÃ©cessaire (localhost suffit)")
    
    lm_model = env_vars.get('LM_MODEL_NAME', 'Auto-dÃ©tectÃ©')
    print(f"   ğŸ¤– LM_MODEL_NAME: {lm_model} {'(intelligent)' if lm_model == 'Auto-dÃ©tectÃ©' else '(manuel)'}")

def configure_provider():
    """Configure le provider LLM"""
    print("\nğŸ¯ CONFIGURATION PROVIDER")
    print("=" * 30)
    print("1. ğŸ¤– Auto (LM Studio localhost â†’ alternatives â†’ OpenAI)")
    print("2. ğŸ  LM Studio uniquement (localhost + fallback)")
    print("3. â˜ï¸ OpenAI uniquement")
    
    try:
        choice = input("\nâ¤ Choisir le provider (1-3): ").strip()
        
        env_vars = load_env()
        
        if choice == "1":
            env_vars["LLM_PROVIDER"] = "auto"
            print("âœ… Provider configurÃ©: Auto (localhost â†’ alternatives â†’ OpenAI)")
        elif choice == "2":
            env_vars["LLM_PROVIDER"] = "lmstudio"
            configure_lm_studio(env_vars)
            print("âœ… Provider configurÃ©: LM Studio")
        elif choice == "3":
            env_vars["LLM_PROVIDER"] = "openai"
            configure_openai(env_vars)
            print("âœ… Provider configurÃ©: OpenAI")
        else:
            print("âŒ Choix invalide")
            return
        
        save_env(env_vars)
        
    except KeyboardInterrupt:
        print("\nâŒ AnnulÃ©")

def configure_openai(env_vars):
    """Configure OpenAI"""
    current_key = env_vars.get('OPENAI_API_KEY', '')
    display_key = f"{current_key[:8]}..." if current_key else "Non configurÃ©"
    
    print(f"\nğŸ”‘ Configuration OpenAI")
    print(f"ClÃ© actuelle: {display_key}")
    
    new_key = input("â¤ Nouvelle clÃ© API (Enter pour garder): ").strip()
    if new_key:
        env_vars['OPENAI_API_KEY'] = new_key

def configure_lm_studio(env_vars):
    """Configure LM Studio avec fallback intelligent"""
    print(f"\nğŸ  Configuration LM Studio")
    
    current_url = env_vars.get('LM_API_URL', 'http://localhost:1234')
    print(f"URL principale: {current_url}")
    new_url = input("â¤ Nouvelle URL principale (Enter pour garder localhost:1234): ").strip()
    if new_url:
        env_vars['LM_API_URL'] = new_url
    
    print(f"\nğŸ’¡ IPs alternatives seulement si vous avez d'autres machines LM Studio")
    current_ips = env_vars.get('LM_ALTERNATIVE_IPS', '')
    if current_ips:
        print(f"IPs alternatives actuelles: {current_ips}")
    else:
        print(f"Aucune IP alternative (localhost suffit gÃ©nÃ©ralement)")
    
    configure_alt = input("â¤ Ajouter des IPs alternatives ? (y/N): ").strip().lower()
    if configure_alt == 'y':
        new_ips = input("â¤ IPs alternatives (sÃ©parÃ©es par virgules, ou Enter pour supprimer): ").strip()
        if new_ips:
            env_vars['LM_ALTERNATIVE_IPS'] = new_ips
        elif 'LM_ALTERNATIVE_IPS' in env_vars:
            del env_vars['LM_ALTERNATIVE_IPS']
    
    current_model = env_vars.get('LM_MODEL_NAME', 'Auto-dÃ©tectÃ©')
    print(f"ModÃ¨le actuel: {current_model}")
    print(f"ğŸ’¡ Laissez vide pour auto-dÃ©tection (recommandÃ©)")
    new_model = input("â¤ Nouveau modÃ¨le spÃ©cifique (Enter pour auto-dÃ©tection): ").strip()
    if new_model:
        env_vars['LM_MODEL_NAME'] = new_model
    elif 'LM_MODEL_NAME' in env_vars:
        # Supprimer la variable pour forcer l'auto-dÃ©tection
        del env_vars['LM_MODEL_NAME']

def test_providers():
    """Test les providers disponibles"""
    print("\nğŸ§ª TEST DES PROVIDERS")
    print("=" * 30)
    
    try:
        # Test du systÃ¨me modulaire
        parent_dir = Path(__file__).parent.parent
        sys.path.append(str(parent_dir / 'core'))
        from llm_providers import get_llm_manager
        
        manager = get_llm_manager()
        info = manager.get_active_provider_info()
        
        print(f"ğŸ¯ Provider actif: {info['provider']}")
        print(f"ğŸ“¡ Disponible: {'âœ…' if info['available'] else 'âŒ'}")
        print(f"ğŸ¤– ModÃ¨les: {len(info['models'])} disponibles")
        
        if info['models']:
            print(f"   ğŸ“‹ Exemples: {', '.join(info['models'][:3])}...")
        
        if info['provider'] == 'lmstudio':
            print(f"ğŸ  URL active: {info.get('active_url', 'N/A')}")
            print(f"ğŸ“¦ ModÃ¨le configurÃ©: {info.get('configured_model', 'N/A')}")
            
            # Indiquer si on utilise localhost ou alternative
            active_url = info.get('active_url', '')
            if 'localhost' in active_url or '127.0.0.1' in active_url:
                print(f"âœ… Utilise localhost (optimal)")
            else:
                print(f"âš ï¸ Utilise IP alternative (localhost non disponible)")
        
        # Test de gÃ©nÃ©ration
        print(f"\nğŸ”„ Test de gÃ©nÃ©ration...")
        response = manager.generate_reply(
            system_prompt="You are a helpful assistant.",
            user_prompt="Say hello briefly",
            max_tokens=20,
            temperature=0.7
        )
        
        if response:
            print(f"âœ… Test rÃ©ussi: \"{response}\"")
        else:
            print(f"âŒ Test Ã©chouÃ©")
            
    except Exception as e:
        print(f"âŒ Erreur test: {e}")

def restart_bot():
    """RedÃ©marre le bot"""
    print("\nğŸ”„ REDÃ‰MARRAGE DU BOT")
    print("=" * 25)
    
    try:
        # Aller dans le rÃ©pertoire parent
        os.chdir(Path(__file__).parent.parent)
        
        # ArrÃªter les processus existants
        print("â¹ï¸ ArrÃªt des processus...")
        subprocess.run(["taskkill", "/F", "/IM", "python.exe"], 
                      capture_output=True, shell=True)
        
        # RedÃ©marrer
        print("ğŸš€ RedÃ©marrage...")
        subprocess.Popen(["python", "main.py"], shell=True)
        
        print("âœ… Bot redÃ©marrÃ© avec la nouvelle configuration")
        
    except Exception as e:
        print(f"âŒ Erreur redÃ©marrage: {e}")

def main():
    """Menu principal"""
    while True:
        print("\n" + "="*60)
        print("ğŸ¤– GESTIONNAIRE MODÃˆLES LLM MODULAIRE")
        print("="*60)
        
        show_current_config()
        
        print(f"\nğŸ“‹ OPTIONS:")
        print(f"   1. ğŸ¯ Configurer Provider (OpenAI/LM Studio)")
        print(f"   2. ğŸŒ¡ï¸ Ajuster tempÃ©rature")
        print(f"   3. ğŸ§ª Tester les providers")
        print(f"   4. ğŸ“Š Voir config complÃ¨te")
        print(f"   5. ğŸ”„ RedÃ©marrer le bot")
        print(f"   6. ğŸšª Quitter")
        
        try:
            choice = input(f"\nâ¤ Votre choix (1-6): ").strip()
            
            if choice == "1":
                configure_provider()
            elif choice == "2":
                change_temperature()
            elif choice == "3":
                test_providers()
            elif choice == "4":
                data = load_prompts()
                env_vars = load_env()
                print(f"\nğŸ”§ CONFIG COMPLÃˆTE:")
                if data:
                    print(f"Prompts: {json.dumps(data['settings']['auto_reply'], indent=2)}")
                print(f"Env: {json.dumps({k:v for k,v in env_vars.items() if k.startswith(('LLM_', 'OPENAI_', 'LM_'))}, indent=2)}")
            elif choice == "5":
                restart_bot()
            elif choice == "6":
                print("ğŸ‘‹ Au revoir!")
                break
            else:
                print("âŒ Choix invalide")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Au revoir!")
            break

def change_temperature():
    """Change la tempÃ©rature du modÃ¨le"""
    try:
        data = load_prompts()
        if not data:
            return
            
        current_temp = data["settings"]["auto_reply"]["temperature"]
        
        temp = input(f"\nğŸŒ¡ï¸ Nouvelle tempÃ©rature (0.1-1.0, actuelle {current_temp}): ").strip()
        
        temp_value = float(temp)
        if 0.1 <= temp_value <= 1.0:
            data["settings"]["auto_reply"]["temperature"] = temp_value
            save_prompts(data)
            
            print(f"âœ… TempÃ©rature changÃ©e vers: {temp_value}")
            if temp_value < 0.3:
                print("ğŸ§Š RÃ©ponses plus conservatrices et prÃ©visibles")
            elif temp_value > 0.8:
                print("ğŸ”¥ RÃ©ponses plus crÃ©atives et variÃ©es")
            else:
                print("âš–ï¸ Bon Ã©quilibre crÃ©ativitÃ©/cohÃ©rence")
        else:
            print("âŒ Valeur invalide (doit Ãªtre entre 0.1 et 1.0)")
            
    except (ValueError, KeyboardInterrupt):
        print("\nâŒ AnnulÃ©")

if __name__ == "__main__":
    main() 