#!/usr/bin/env python3
"""
Test pour vÃ©rifier la cohÃ©rence de la configuration LM Studio
VÃ©rifie que tous les fichiers de config sont synchronisÃ©s
"""

import json
import os

class TestLMStudioConsistency:
    def __init__(self):
        print("ğŸ”§ Test CohÃ©rence Configuration LM Studio")
        print("=" * 60)
        
    def test_config_files_consistency(self):
        """Test la cohÃ©rence entre config.json et prompts.json"""
        print("\n1. ğŸ” Test CohÃ©rence Config Files")
        print("-" * 40)
        
        try:
            # Charger config.json
            with open('config/config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # Charger prompts.json
            with open('config/prompts.json', 'r', encoding='utf-8') as f:
                prompts = json.load(f)
            
            print("ğŸ“„ Configuration actuelle:")
            
            # VÃ©rifier config.json
            content_gen = config['content_generation']
            print(f"   config.json - Provider: {content_gen['provider']}")
            print(f"   config.json - Model: {content_gen['model']}")
            
            # VÃ©rifier prompts.json  
            tweet_settings = prompts['settings']['tweet_generation']
            reply_settings = prompts['settings']['auto_reply']
            print(f"   prompts.json Tweet - Provider: {tweet_settings['provider']}")
            print(f"   prompts.json Tweet - Model: {tweet_settings['model']}")
            print(f"   prompts.json Reply - Provider: {reply_settings['provider']}")
            print(f"   prompts.json Reply - Model: {reply_settings['model']}")
            
            # VÃ©rifications de cohÃ©rence
            consistency_checks = [
                ("config.json utilise 'auto'", content_gen['provider'] == 'auto'),
                ("config.json utilise gpt-4o-mini", content_gen['model'] == 'gpt-4o-mini'),
                ("prompts.json tweet utilise 'auto'", tweet_settings['provider'] == 'auto'),
                ("prompts.json tweet utilise gpt-4o-mini", tweet_settings['model'] == 'gpt-4o-mini'),
                ("prompts.json reply utilise 'auto'", reply_settings['provider'] == 'auto'),
                ("prompts.json reply utilise gpt-4o-mini", reply_settings['model'] == 'gpt-4o-mini'),
                ("Force LLM activÃ©", reply_settings.get('force_llm', False))
            ]
            
            print("\nğŸ” VÃ©rifications cohÃ©rence:")
            all_consistent = True
            for check_name, check_result in consistency_checks:
                status = "âœ…" if check_result else "âŒ"
                print(f"   {status} {check_name}")
                if not check_result:
                    all_consistent = False
            
            return all_consistent
            
        except Exception as e:
            print(f"âŒ Erreur test cohÃ©rence: {e}")
            return False
    
    def test_lmstudio_optimization(self):
        """Test des optimisations spÃ©cifiques Ã  LM Studio"""
        print("\n2. âš¡ Test Optimisations LM Studio")
        print("-" * 40)
        
        try:
            with open('config/prompts.json', 'r', encoding='utf-8') as f:
                prompts = json.load(f)
            
            reply_settings = prompts['settings']['auto_reply']
            
            # VÃ©rifications optimisations LM Studio
            optimizations = [
                ("TempÃ©rature Ã©levÃ©e (crÃ©ativitÃ©)", reply_settings['temperature'] >= 0.8),
                ("Max tokens limitÃ©s (rapiditÃ©)", reply_settings['max_tokens'] <= 100),
                ("Force LLM activÃ©", reply_settings.get('force_llm', False)),
                ("ModÃ¨les alternatifs dÃ©finis", len(reply_settings.get('alternative_models', [])) > 0)
            ]
            
            print("âš¡ Optimisations LM Studio:")
            all_optimized = True
            for opt_name, opt_result in optimizations:
                status = "âœ…" if opt_result else "âŒ"
                print(f"   {status} {opt_name}")
                if not opt_result:
                    all_optimized = False
            
            return all_optimized
            
        except Exception as e:
            print(f"âŒ Erreur test optimisations: {e}")
            return False
    
    def test_fallback_configuration(self):
        """Test de la configuration fallback"""
        print("\n3. ğŸ”„ Test Configuration Fallback")
        print("-" * 40)
        
        try:
            with open('config/prompts.json', 'r', encoding='utf-8') as f:
                prompts = json.load(f)
            
            reply_settings = prompts['settings']['auto_reply']
            alternative_models = reply_settings.get('alternative_models', [])
            
            print(f"ğŸ“‹ ModÃ¨les alternatifs: {alternative_models}")
            
            # VÃ©rifications fallback
            fallback_checks = [
                ("gpt-4o-mini dans fallback", "gpt-4o-mini" in alternative_models),
                ("gpt-4o dans fallback", "gpt-4o" in alternative_models),
                ("Au moins 3 modÃ¨les fallback", len(alternative_models) >= 3),
                ("Provider 'auto' pour fallback", prompts['settings']['tweet_generation']['provider'] == 'auto')
            ]
            
            print("ğŸ”„ Configuration fallback:")
            all_fallback_ok = True
            for check_name, check_result in fallback_checks:
                status = "âœ…" if check_result else "âŒ"
                print(f"   {status} {check_name}")
                if not check_result:
                    all_fallback_ok = False
            
            return all_fallback_ok
            
        except Exception as e:
            print(f"âŒ Erreur test fallback: {e}")
            return False
    
    def run_all_tests(self):
        """Lance tous les tests de cohÃ©rence"""
        tests = [
            ("CohÃ©rence Config Files", self.test_config_files_consistency),
            ("Optimisations LM Studio", self.test_lmstudio_optimization),
            ("Configuration Fallback", self.test_fallback_configuration)
        ]
        
        results = []
        
        for test_name, test_func in tests:
            print(f"\nğŸ§ª {test_name}...")
            try:
                result = test_func()
                results.append((test_name, result))
                status = "âœ… PASSÃ‰" if result else "âŒ Ã‰CHOUÃ‰"
                print(f"   {status}")
            except Exception as e:
                print(f"   âŒ ERREUR: {e}")
                results.append((test_name, False))
        
        # RÃ©sumÃ©
        print("\n" + "=" * 60)
        print("ğŸ“Š RÃ‰SUMÃ‰ COHÃ‰RENCE LM STUDIO")
        print("=" * 60)
        
        passed = sum(1 for _, result in results if result)
        total = len(results)
        
        for test_name, result in results:
            status = "âœ…" if result else "âŒ"
            print(f"{status} {test_name}")
        
        print(f"\nğŸ¯ Score: {passed}/{total} tests passÃ©s")
        
        if passed == total:
            print("ğŸ‰ CONFIGURATION PARFAITEMENT HARMONISÃ‰E !")
            print("\nğŸ”§ Configuration LM Studio complÃ¨te:")
            print("   1. âœ… Provider 'auto' partout (dÃ©tection LM Studio)")
            print("   2. âœ… ModÃ¨le gpt-4o-mini cohÃ©rent")
            print("   3. âœ… Fallback automatique configurÃ©")
            print("   4. âœ… Optimisations LM Studio actives")
            print("   5. âœ… Force LLM pour les rÃ©ponses")
        else:
            print("âš ï¸ Des incohÃ©rences persistent.")
        
        return passed == total

if __name__ == "__main__":
    # VÃ©rifier que les fichiers existent
    if not os.path.exists('config/config.json') or not os.path.exists('config/prompts.json'):
        print("âŒ Erreur: Fichiers de configuration manquants")
        exit(1)
    
    tester = TestLMStudioConsistency()
    success = tester.run_all_tests()
    
    if success:
        print("\nâœ… Votre configuration est optimale pour LM Studio !")
        print("ğŸ’¡ Le bot utilisera LM Studio en prioritÃ© avec fallback OpenAI.")
    else:
        print("\nâŒ Configuration incomplÃ¨te.")
    
    exit(0 if success else 1) 